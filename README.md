# Efficient Ralph Loops

Runs Codex / Claude Code in a bash loop inside Docker until the project marks itself done. Two scripts—one for OpenAI Codex, one for Anthropic Claude—mount your project, feed instructions, and exit when the done pattern appears in the TODO file.

## Why?

Ralph loops work well! Sometimes... And they have issues:

- Ralph loops are inefficient and burn tokens quickly.
- Agents WILL write bad tests just to satisfy exit conditions.
- Context resets each loop with no memory of what was tried.
- Without a clear plan, the agent zig-zags between competing ideas / features.
- Without commits, you lose intermediate progress and figure out which change broke things.
- Long-running sessions accumulate context that degrades performance and burns tokens.

Efficient Ralph Loops adds structure:

- **One task per iteration.** Agent works from a prioritized TODO list. Each iteration targets exactly one task—no scope creep, no multi-task confusion.
- **Clear acceptance criteria.** Each task has a spec with explicit verification steps. The agent knows what "done" looks like before it starts.
- **Fresh context every loop.** The iteration ends once the task is complete. The agent starts the next task with a clean context window. This prevents context pollution, improves reasoning quality, and reduces token usage.
- **Git commits between iterations.** Every completed task is committed before the next iteration starts. You preserve intermediate progress, can review diffs, and can identify when something breaks.
- **Explicit termination.** Loop stops only when `TODO.md` contains `[x] ALL_TASKS_COMPLETE`.
- **Docker isolation.** The agent runs with full permissions inside a container. It can't touch anything outside the mounted project directory, allowing true autonomous 12-hour runs without you worrying about rm -rf on your ~/home directory.


The result is a workflow that looks more like real engineering: a prioritized backlog, small verifiable tasks, incremental commits, and clear completion criteria.


## Contents

- `Dockerfile` — builds `agent-loop` image (Node 20 + `@openai/codex` + `@anthropic-ai/claude-code`)
- `loop-codex.sh` — Codex loop
- `loop-claude.sh` — Claude loop
- `YOUR_PROJECT/` — sample scaffold (PLAN/TODO/task templates + bootstrap)
- `LICENSE` — MIT

## Prerequisites

- Docker
- API key or subscription auth (see below)

## Build
```sh
docker build -t agent-loop .
```

---

## Initialization: bootstrapping a new project

The loop expects this structure:
```text
your-project/
  PLAN.md                         # goals, constraints, approach
  INSTRUCTIONS.md                 # per-iteration prompt
  TODO.md                         # generated by $bootstrap or /bootstrap
  docs/tasks/active/...           # generated by $bootstrap or /bootstrap
  .codex/skills/bootstrap/SKILL.md   # enables $bootstrap in Codex
  .claude/commands/bootstrap.md      # enables /bootstrap in Claude Code
```

`YOUR_PROJECT/` contains a working example. Copy it or use it as reference.

### 1. Write PLAN.md

Not a task list. It's the "what" and "why": goals, constraints, technical approach, expected outputs. The bootstrap command splits it into tasks.

### 2. Add the bootstrap command

Include one or both:

- **Codex:** `.codex/skills/bootstrap/SKILL.md`
- **Claude:** `.claude/commands/bootstrap.md`

Both are provided in `YOUR_PROJECT/`.

### 3. Generate TODO.md

Run your agent interactively (not in the Docker loop) and invoke the bootstrap command.

**Codex:**
```sh
cd your-project
codex
```

Then type `$bootstrap`.

**Claude:**
```sh
cd your-project
claude
```

Then type `/bootstrap`.

Review the generated `TODO.md` and task specs. Adjust as needed before running the loop.

### 4. Tune INSTRUCTIONS.md

Make verification explicit for your stack:

- `npm test && npm run build`
- `go test ./...`
- `pytest -q`

If the agent can't verify its work in-container, it will game the process.

---

## Usage

Scripts mount `PROJECT_DIR` as `/workspace`, read `INSTRUCTIONS.md`, and poll `TODO.md` for `[x] ALL_TASKS_COMPLETE`.

### Codex
```sh
CODEX_API_KEY=sk-... ./loop-codex.sh
# or
OPENAI_API_KEY=sk-... ./loop-codex.sh
```

### Claude (API key)
```sh
ANTHROPIC_API_KEY=sk-... ./loop-claude.sh
# or
CLAUDE_API_KEY=sk-... ./loop-claude.sh
```

### Claude (subscription auth - macOS)
```sh
# One-time: extract OAuth token from keychain
mkdir -p ~/.claude
security find-generic-password -s "Claude Code-credentials" -w > ~/.claude/.credentials.json
```

Then:
```sh
./loop-claude.sh
```

Script mounts `~/.claude` and `~/.claude.json` automatically.

---

## Options

| Flag | Description |
|------|-------------|
| `--dry-run` | Print config, don't run |
| `--once` | Single iteration |

| Variable | Default | Description |
|----------|---------|-------------|
| `PROJECT_DIR` | `./YOUR_PROJECT` | Project path |
| `INSTRUCTIONS_FILE` | `$PROJECT_DIR/INSTRUCTIONS.md` | Agent instructions |
| `DONE_FILE` | `$PROJECT_DIR/TODO.md` | Completion file |
| `DONE_PATTERN` | `\[x\] ALL_TASKS_COMPLETE` | Done regex |
| `SLEEP_SECONDS` | `2` | Loop delay |
| `MAX_LOOPS` | `0` | Iteration cap (0 = unlimited) |
| `STDOUT_MODE` | `stream` | `stream`, `quiet`, `log`, `log_only` |
| `LOG_DIR` | `./logs` | Log output dir |
| `IMAGE` | `agent-loop:latest` | Docker image |
| `MODEL` | `opus` | Claude model |

---

## Task format

The loop stops when `DONE_FILE` contains:
```md
- [x] ALL_TASKS_COMPLETE
```

Tasks should be small enough that "do one, verify, commit" is realistic. Each spec needs a verification section the agent can actually execute.

---

## Security

The agent runs with full permissions inside the container (`--dangerously-bypass-approvals-and-sandbox` for Codex, `--dangerously-skip-permissions` for Claude). This is intentional—Docker provides the isolation, so the agent can work autonomously without approval prompts slowing it down.

The host filesystem is not at risk. Only the mounted project directory is accessible. 

Why this matters: [Google Antigravity wiped a user's entire D: drive](https://old.reddit.com/r/google_antigravity/comments/1p82or6/google_antigravity_just_deleted_the_contents_of/) when asked to clear a cache. Docker prevents this—only the mounted project directory is accessible.

---

## License

MIT. See `LICENSE`.

---

## Acknowledgements

This project is heavily inspired by the “Ralph loop” pattern popularized by Geoffrey Huntley, and by the broader ecosystem of Ralph-loop implementations and writeups.

Additional influences:
- **Ralph loops** — the core “run an agent in a loop with fresh context, tight scope, and checkpoints” idea (see Geoffrey Huntley’s writeup: https://ghuntley.com/ralph/).
- **Ralph implementations/playbooks** — practical references that helped shape details of the loop + workflow:
  - https://github.com/snarktank/ralph
  - https://github.com/ClaytonFarr/ralph-playbook
- **Shrivu Shankar — “AI Can’t Read Your Docs”** — for clear thinking on designing software and interfaces that today’s coding agents can reliably navigate: https://blog.sshh.io/p/ai-cant-read-your-docs
- **Steve Yegge — Beads** — even though this repo doesn’t use Beads directly, the “externalize state so agents can resume cleanly” philosophy strongly influenced the structure here:
  - https://github.com/steveyegge/beads
  - https://steve-yegge.medium.com/introducing-beads-a-coding-agent-memory-system-637d7d92514a
- **Manus “todo.md” workflow** — the idea of continuously updating a checklist to keep the global plan in the model’s recent attention:
  - https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus
